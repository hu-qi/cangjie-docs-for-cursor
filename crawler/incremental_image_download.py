#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢é‡å›¾ç‰‡ä¸‹è½½è„šæœ¬ - ä¸ºç°æœ‰æ–‡æ¡£ä¸‹è½½ç¼ºå¤±çš„å›¾ç‰‡
"""

import asyncio
import re
import sys
from pathlib import Path
from urllib.parse import urljoin

# æ·»åŠ crawlerç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from image_downloader import ImageDownloader
from playwright.async_api import async_playwright


class IncrementalImageDownloader:
    def __init__(self, version="1.0.1", base_url=None, output_dir="../docs"):
        self.version = version
        self.base_url = base_url or f"https://docs.cangjie-lang.cn/docs/{version}/"
        self.output_dir = Path(output_dir)
        self.version_dir = self.output_dir / version
        self.image_downloader = ImageDownloader(self.base_url, str(self.output_dir), version)
    
    def find_markdown_files_with_images(self):
        """æŸ¥æ‰¾åŒ…å«å›¾ç‰‡å¼•ç”¨çš„Markdownæ–‡ä»¶"""
        md_files_with_images = []
        
        # å›¾ç‰‡å¼•ç”¨æ¨¡å¼
        img_pattern = r'!\[([^\]]*)\]\(([^)]+)\)'
        
        for md_file in self.version_dir.rglob("*.md"):
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æŸ¥æ‰¾å›¾ç‰‡å¼•ç”¨
                matches = re.findall(img_pattern, content)
                if matches:
                    # è¿‡æ»¤å‡ºç›¸å¯¹è·¯å¾„çš„å›¾ç‰‡ï¼ˆéœ€è¦ä¸‹è½½çš„ï¼‰
                    local_images = []
                    for alt, src in matches:
                        if src.startswith('./') or (not src.startswith('http') and '/' in src):
                            local_images.append((alt, src))
                    
                    if local_images:
                        relative_path = md_file.relative_to(self.version_dir)
                        md_files_with_images.append({
                            'md_file': md_file,
                            'relative_path': str(relative_path),
                            'images': local_images
                        })
                        
            except Exception as e:
                print(f"âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥ {md_file}: {e}")
        
        return md_files_with_images
    
    async def download_page_html(self, url):
        """ä¸‹è½½æŒ‡å®šURLçš„HTMLå†…å®¹"""
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context(
                user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
            )
            
            page = await context.new_page()
            
            try:
                response = await page.goto(url, wait_until="networkidle")
                if response.status == 200:
                    html_content = await page.content()
                    return html_content
                else:
                    print(f"âŒ é¡µé¢è®¿é—®å¤±è´¥: {url} (çŠ¶æ€ç : {response.status})")
                    return None
            except Exception as e:
                print(f"âŒ è®¿é—®é¡µé¢å‡ºé”™ {url}: {e}")
                return None
            finally:
                await browser.close()
    
    async def process_files_with_images(self, max_files=None):
        """å¤„ç†åŒ…å«å›¾ç‰‡çš„æ–‡ä»¶ï¼Œä¸‹è½½ç¼ºå¤±çš„å›¾ç‰‡"""
        
        print("ğŸ” æ‰«æåŒ…å«å›¾ç‰‡çš„Markdownæ–‡ä»¶...")
        md_files = self.find_markdown_files_with_images()
        
        if not md_files:
            print("ğŸ“„ æ²¡æœ‰æ‰¾åˆ°åŒ…å«æœ¬åœ°å›¾ç‰‡å¼•ç”¨çš„Markdownæ–‡ä»¶")
            return
        
        print(f"ğŸ“„ æ‰¾åˆ° {len(md_files)} ä¸ªåŒ…å«å›¾ç‰‡çš„æ–‡ä»¶")
        
        if max_files:
            md_files = md_files[:max_files]
            print(f"ğŸ¯ é™åˆ¶å¤„ç†å‰ {max_files} ä¸ªæ–‡ä»¶")
        
        # å‡†å¤‡ä¸‹è½½æ•°æ®
        download_data = []
        
        for file_info in md_files:
            relative_path = file_info['relative_path']
            images = file_info['images']
            
            print(f"ğŸ“ å¤„ç†æ–‡ä»¶: {relative_path} ({len(images)} ä¸ªå›¾ç‰‡)")
            
            # æ„é€ å¯¹åº”çš„HTMLé¡µé¢URL
            html_url = urljoin(self.base_url, relative_path.replace('.md', '.html'))
            
            # ä¸‹è½½HTMLå†…å®¹
            html_content = await self.download_page_html(html_url)
            
            if html_content:
                download_data.append({
                    'html_content': html_content,
                    'page_url': html_url,
                    'markdown_file_path': relative_path
                })
            else:
                print(f"âš ï¸  è·³è¿‡æ–‡ä»¶ {relative_path}ï¼šæ— æ³•è·å–HTMLå†…å®¹")
        
        # æ‰¹é‡ä¸‹è½½å›¾ç‰‡
        if download_data:
            print(f"\nğŸ–¼ï¸  å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(download_data)} ä¸ªé¡µé¢çš„å›¾ç‰‡...")
            
            image_mappings = await self.image_downloader.download_all_images(download_data)
            
            # æ›´æ–°Markdownæ–‡ä»¶ä¸­çš„å›¾ç‰‡è·¯å¾„
            updated_files = 0
            for file_info in md_files:
                relative_path = file_info['relative_path']
                md_file = file_info['md_file']
                
                if relative_path in image_mappings:
                    try:
                        # è¯»å–åŸæ–‡ä»¶
                        with open(md_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # æ›´æ–°å›¾ç‰‡è·¯å¾„
                        updated_content = self.image_downloader.update_markdown_image_paths(
                            content, image_mappings[relative_path]
                        )
                        
                        # å¦‚æœæœ‰æ›´æ–°ï¼Œå†™å›æ–‡ä»¶
                        if updated_content != content:
                            with open(md_file, 'w', encoding='utf-8') as f:
                                f.write(updated_content)
                            
                            print(f"âœ… æ›´æ–°æ–‡ä»¶: {relative_path}")
                            updated_files += 1
                        
                    except Exception as e:
                        print(f"âŒ æ›´æ–°æ–‡ä»¶å¤±è´¥ {relative_path}: {e}")
            
            print(f"\nğŸ‰ å¤„ç†å®Œæˆ!")
            print(f"ğŸ“Š æ›´æ–°äº† {updated_files} ä¸ªMarkdownæ–‡ä»¶")
        
        else:
            print("âŒ æ²¡æœ‰æˆåŠŸè·å–ä»»ä½•HTMLå†…å®¹ï¼Œæ— æ³•ä¸‹è½½å›¾ç‰‡")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å¢é‡ä¸‹è½½æ–‡æ¡£å›¾ç‰‡')
    parser.add_argument('--version', '-v', default='1.0.1', help='ä»“é¢‰ç‰ˆæœ¬å·')
    parser.add_argument('--max-files', '-m', type=int, help='æœ€å¤§å¤„ç†æ–‡ä»¶æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    parser.add_argument('--output', '-o', default='../docs', help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ å¼€å§‹å¢é‡ä¸‹è½½ä»“é¢‰ {args.version} ç‰ˆæœ¬æ–‡æ¡£å›¾ç‰‡...")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output}")
    
    downloader = IncrementalImageDownloader(
        version=args.version,
        output_dir=args.output
    )
    
    await downloader.process_files_with_images(max_files=args.max_files)


if __name__ == "__main__":
    asyncio.run(main())